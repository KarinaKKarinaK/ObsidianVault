
---

## Lecture Goals

- Review limits of simple quadratic-time sorting.
    
- Introduce the **Divide-and-Conquer** paradigm.
    
- Study **MergeSort** in detail:
    
    - Pseudocode, correctness, runtime analysis.
        
- Understand why **comparison-based sorting** cannot beat Î©(n log n).
    

---

## 4.1 Motivation

- Insertion Sort, Selection Sort, Bubble Sort = O(nÂ²).
    
- Too slow for large n.
    
- Need faster algorithms.
    
- Divide-and-Conquer gives powerful framework to break O(nÂ²) barrier.
    

---

## 4.2 Divide-and-Conquer Paradigm

**General recipe:**

1. **Divide** problem into smaller subproblems.
    
2. **Conquer**: solve each recursively.
    
3. **Combine**: merge solutions.
    

Many fast algorithms rely on this (MergeSort, QuickSort, FFT, Strassen).

---

## 4.3 MergeSort

### Algorithm idea

- To sort array A[1..n]:
    
    1. Divide into two halves A[1..n/2], A[n/2+1..n].
        
    2. Recursively sort each half.
        
    3. Merge two sorted halves into sorted array.
        

### Pseudocode

```python
def MergeSort(A, l, r):
    if l < r:
        m = âŒŠ(l + r)/2âŒ‹
        MergeSort(A, l, m)
        MergeSort(A, m+1, r)
        Merge(A, l, m, r)

def Merge(A, l, m, r):
    n1 = m - l + 1
    n2 = r - m
    L = A[l..m]
    R = A[m+1..r]
    i = j = 0
    k = l
    while i < n1 and j < n2:
        if L[i] â‰¤ R[j]:
            A[k] = L[i]
            i += 1
        else:
            A[k] = R[j]
            j += 1
        k += 1
    # Copy remaining elements
    while i < n1:
        A[k] = L[i]; i+=1; k+=1
    while j < n2:
        A[k] = R[j]; j+=1; k+=1
```

### Correctness (loop invariant of Merge)

- At each iteration, A[l..kâˆ’1] contains smallest kâˆ’l elements of LâˆªR in sorted order.
    
- Initialization: holds before any elements copied.
    
- Maintenance: next smallest chosen correctly.
    
- Termination: all elements copied.
    

âœ… Correct.

---

## 4.4 MergeSort Example

Input: [5,2,4,7,1,3,2,6]

- Divide into [5,2,4,7] and [1,3,2,6].
    
- Recursively sort â†’ [2,4,5,7] and [1,2,3,6].
    
- Merge â†’ [1,2,2,3,4,5,6,7].
    

---

## 4.5 Runtime Analysis

Recurrence:

```
T(n) = 2T(n/2) + Î˜(n)
```

- Dividing = constant.
    
- Conquering = 2 recursive calls.
    
- Combining = merge = Î˜(n).
    

### Recursion tree

- Height = logâ‚‚n.
    
- Each level = Î˜(n).
    
- Total = Î˜(n log n).
    

### Space

- Needs Î˜(n) auxiliary space (for temporary arrays).
    

---

## 4.6 Comparison-Based Sorting Lower Bound

### Model: decision tree

- Sorting by comparisons = binary decision tree.
    
- Each internal node = comparison between two elements.
    
- Each leaf = one permutation of n elements.
    

### Argument

- Tree must have â‰¥ n! leaves (all orderings possible).
    
- Binary tree of height h has â‰¤ 2^h leaves.
    
- So 2^h â‰¥ n! â†’ h â‰¥ logâ‚‚(n!).
    
- By Stirlingâ€™s approximation: logâ‚‚(n!) = Î˜(n log n).
    

Thus: any comparison-based sorting requires Î©(n log n).

### Implication

- MergeSortâ€™s Î˜(n log n) is **asymptotically optimal**.
    
- QuickSort, HeapSort also achieve this.
    

---

## ðŸ”‘ Lecture IV Upshot

- Divide-and-Conquer is a universal algorithm design technique.
    
- **MergeSort** sorts in Î˜(n log n), much better than quadratic sorts.
    
- Proof of correctness relies on loop invariants.
    
- Decision tree argument â†’ no comparison sort beats Î©(n log n).
    
- Therefore MergeSort is optimal within comparison-based framework.
    

---

## ðŸŽ“ Exam / Interview Tips

- Write MergeSort + Merge pseudocode cleanly.
    
- Prove correctness with loop invariant.
    
- Derive recurrence T(n) = 2T(n/2) + Î˜(n).
    
- Solve recurrence using recursion tree or Master Theorem.
    
- Explain decision-tree lower bound argument clearly.
    

---

## ðŸ§  Common Pitfalls

- Forgetting to copy leftover elements after merge loop.
    
- Miscomputing recurrence (e.g., T(n)=T(n/2)+Î˜(n) â†’ wrong answer).
    
- Confusing Î©(n log n) lower bound with O(n log n) upper bound.
    
- Ignoring auxiliary space c