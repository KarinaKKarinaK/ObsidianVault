## Introduction to research in psychology

- **Why research is crucial**: Psychological science relies on the **scientific method** to ensure that its conclusions are reliable and valid. Research helps us move beyond intuition and bias, providing evidence-based answers to questions about human thought and behavior.

- %% fold %% **The Scientific Method**:
	1. **Observation**: Noticing a phenomenon and asking questions about it.
	2. **Hypothesis**: Formulating a testable prediction about how variables are related.
	3. **Experimentation**: Testing the hypothesis by manipulating variables in a controlled setting.
	4. **Conclusion**: Analyzing the data to determine if the hypothesis was supported or rejected.

## Types of research methods

1. %% fold %% **Descriptive Studies**:

	- **Purpose**: To observe and describe behavior without manipulating variables.
	- **Types of descriptive studies**:
	
		- **Naturalistic observation**: Observing behavior in its natural setting without interference (e.g., watching children play on a playground to study social interactions).
		- **Case studies**: In-depth analysis of a single individual or small group, often used to study rare conditions (e.g., a patient with a rare brain injury).
		- **Surveys**: Gathering data from a large group of people through questionnaires or interviews. It is a good way to gather information on attitudes, beliefs, or self-reported behaviors.
	
	- **Limitation**: Descriptive methods only describe behavior; they do not explain **why** the behavior occurs.

2. %% fold %% **Correlational Studies**:

	- **Purpose**: To determine if there is a relationship between two variables and how strong that relationship is.
	
	- **Correlation Coefficient (r)**: A statistical measure that shows the strength and direction of the relationship between two variables. The value of **r** ranges from **-1.0** to **+1.0**:
	
		- **+1.0**: Perfect positive correlation (as one variable increases, the other also increases).
		- **-1.0**: Perfect negative correlation (as one variable increases, the other decreases).
		- **0**: No correlation.
	
	- **Important**: **Correlation does not imply causation**. Even if two variables are correlated, it does not mean that one causes the other. There could be a third variable that influences both.

3. %% fold %% **Experimental Studies**:

	- **Purpose**: To establish a cause-and-effect relationship by manipulating one variable to see its effect on another.
	
	- **Key Concepts**: #trytorecall 
	
		- **Independent variable (IV)**: The variable that is manipulated by the researcher.
		- **Dependent variable (DV)**: The outcome variable that is measured to see the effect of the IV.
		- **Control group**: A group that does not receive the experimental treatment, used for comparison.
		- **Random assignment**: Participants are randomly assigned to either the experimental or control group to eliminate biases.
	
	- **Example**: A study testing whether exercise improves mood could randomly assign participants to either a group that exercises regularly (experimental group) or a group that doesn’t exercise (control group), then measure their mood (dependent variable).

## Key research concepts

#trytorecall 

1. %% fold %% **Operational definitions**:

	- The precise way in which a variable is defined and measured in a study. This is important for clarity and replication.
	
		- **Example**: If studying "aggression," researchers must specify how they define and measure aggression—such as the number of times someone shouts in a given time period.

2. %% fold %% **Control Groups and random assignment**:

	- **Control group**: Essential in experiments to compare results. Without a control group, researchers can’t determine if the change in the dependent variable was due to the independent variable or another factor.
	
	- **Random assignment**: This ensures that participants have an equal chance of being placed in any group, which helps control for **confounding variables** (other factors that could influence the results).

3. %% fold %% **Confounds**:
	
	- Variables other than the independent variable that might influence the dependent variable, thus "confounding" the results.
	
		- **Example**: If testing whether a new teaching method improves learning, but students in the experimental group have more study materials than the control group, the results could be due to the extra materials (a confound) rather than the teaching method.

## Evaluating research

1. %% fold %% **Reliability**:

	- The consistency of a measure. A study is reliable if repeating the study under the same conditions produces similar results.
	
		- **Example**: A reliable intelligence test should produce the same score for a person if they take the test multiple times under the same conditions.

2. %% fold %% **Validity**:

	- The extent to which a study or test measures what it claims to measure.
	
	- **Types of Validity**:
		- **Internal validity**: The degree to which an experiment shows that the independent variable caused changes in the dependent variable.
		- **External validity**: The extent to which the findings can be generalized to other settings, populations, or times.

3. %% fold %% **Replicability**:

	- A study’s results are considered more valid if other researchers can replicate the study and obtain similar results. This ensures that the findings are not due to chance.

## Ethics in research

1. %% fold %% **Informed Consent**:

	- Participants must be fully informed about the nature of the research, including any potential risks, before they agree to participate.\
	
		- **Purpose**: Ensures that participation is voluntary and that participants understand what the study entails.

2. %% fold %% **Confidentiality**:

	-  Researchers must protect the privacy of participants and keep their data confidential.

3. %% fold %% **Debriefing**:

	- After the study is completed, researchers must explain the purpose of the study to the participants and reveal any deception that was used.
	
		- **Purpose**: Ensures that participants leave the study without any misunderstanding or harm caused by the study.

## Interpreting research results

1. %% fold %% **Statistical Significance**:

	- A result is statistically significant if it is unlikely to have occurred by chance. A common threshold is **p < 0.05**, meaning there is less than a 5% chance that the results are due to random variation.

2. %% fold %% **Effect Size**:

	- A measure of the strength of the relationship between two variables. Larger effect sizes indicate stronger relationships.

3. %% fold %% **Meta-analysis**:

	- A statistical technique that combines the results of multiple studies to draw broader conclusions. It helps researchers identify patterns across different studies, increasing the reliability of findings.